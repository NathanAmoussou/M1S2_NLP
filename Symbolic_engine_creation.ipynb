{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "object address  : 0x1130f1ba0\n",
      "object refcount : 2\n",
      "object type     : 0x10d41f210\n",
      "object type name: KeyboardInterrupt\n",
      "object repr     : KeyboardInterrupt()\n",
      "lost sys.stderr\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/nathan/Library/Python/3.11/lib/python/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/nathan/Library/Python/3.11/lib/python/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/nathan/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/nathan/Library/Python/3.11/lib/python/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/nathan/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/nathan/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/nathan/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/nathan/Library/Python/3.11/lib/python/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/nathan/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/nathan/Library/Python/3.11/lib/python/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/nathan/Library/Python/3.11/lib/python/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/nathan/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/nathan/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/nathan/Library/Python/3.11/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/nathan/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/nathan/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/nathan/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/5t/77z6brvj1wqdf_bkh25x0vhc0000gn/T/ipykernel_16355/264445456.py\", line 3, in <module>\n",
      "    import spacy\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/spacy/__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/spacy/errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/spacy/compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/thinc/__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/thinc/config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/thinc/types.py\", line 25, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/thinc/compat.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy loaded successfully!\n",
      "Using NumPy version: 2.2.4\n",
      "Processed sentence: This is a test sentence.\n",
      "This PRON\n",
      "is AUX\n",
      "a DET\n",
      "test NOUN\n",
      "sentence NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Spacy & Numpy import & test.\"\"\"\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    # Load the small English model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"spaCy loaded successfully!\")\n",
    "    print(f\"Using NumPy version: {np.__version__}\") # Check NumPy version\n",
    "\n",
    "    # Test it\n",
    "    doc = nlp(\"This is a test sentence.\")\n",
    "    print(\"Processed sentence:\", doc.text)\n",
    "    for token in doc:\n",
    "        print(token.text, token.pos_)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 'en_core_web_sm' spaCy model.\n",
      "\n",
      "--- Analyzing Query: 'Top 10 most valuable American IT companies.' ---\n",
      "Token           | Lemma           | POS     | Dep        | Detailed Tag | Entity Type\n",
      "--------------------------------------------------------------------------------\n",
      "Top             | top             | ADJ     | ROOT       | JJ           | -\n",
      "10              | 10              | NUM     | nummod     | CD           | CARDINAL\n",
      "most            | most            | ADV     | advmod     | RBS          | -\n",
      "valuable        | valuable        | ADJ     | amod       | JJ           | -\n",
      "American        | american        | ADJ     | amod       | JJ           | NORP\n",
      "IT              | IT              | PROPN   | compound   | NNP          | -\n",
      "companies       | company         | NOUN    | npadvmod   | NNS          | -\n",
      ".               | .               | PUNCT   | punct      | .            | -\n",
      "\n",
      "Base Named Entities Found:\n",
      "- Entity: '10', Label: CARDINAL (Numerals that do not fall under another type)\n",
      "- Entity: 'American', Label: NORP (Nationalities or religious or political groups)\n",
      "================================================================================\n",
      "\n",
      "--- Analyzing Query: 'Show details for Apple Inc.' ---\n",
      "Token           | Lemma           | POS     | Dep        | Detailed Tag | Entity Type\n",
      "--------------------------------------------------------------------------------\n",
      "Show            | show            | VERB    | ROOT       | VB           | -\n",
      "details         | detail          | NOUN    | dobj       | NNS          | -\n",
      "for             | for             | ADP     | prep       | IN           | -\n",
      "Apple           | Apple           | PROPN   | compound   | NNP          | ORG\n",
      "Inc.            | Inc.            | PROPN   | pobj       | NNP          | ORG\n",
      "\n",
      "Base Named Entities Found:\n",
      "- Entity: 'Apple Inc.', Label: ORG (Companies, agencies, institutions, etc.)\n",
      "================================================================================\n",
      "\n",
      "--- Analyzing Query: 'Every French company valued over 1B.' ---\n",
      "Token           | Lemma           | POS     | Dep        | Detailed Tag | Entity Type\n",
      "--------------------------------------------------------------------------------\n",
      "Every           | every           | DET     | det        | DT           | -\n",
      "French          | french          | ADJ     | amod       | JJ           | NORP\n",
      "company         | company         | NOUN    | ROOT       | NN           | -\n",
      "valued          | value           | VERB    | acl        | VBN          | -\n",
      "over            | over            | ADP     | prep       | IN           | -\n",
      "1B.             | 1b.             | NUM     | pobj       | CD           | -\n",
      "\n",
      "Base Named Entities Found:\n",
      "- Entity: 'French', Label: NORP (Nationalities or religious or political groups)\n",
      "================================================================================\n",
      "\n",
      "--- Analyzing Query: 'List all sectors available.' ---\n",
      "Token           | Lemma           | POS     | Dep        | Detailed Tag | Entity Type\n",
      "--------------------------------------------------------------------------------\n",
      "List            | list            | VERB    | ROOT       | VB           | -\n",
      "all             | all             | DET     | det        | DT           | -\n",
      "sectors         | sector          | NOUN    | dobj       | NNS          | -\n",
      "available       | available       | ADJ     | oprd       | JJ           | -\n",
      ".               | .               | PUNCT   | punct      | .            | -\n",
      "\n",
      "Base Named Entities Found:\n",
      "- No named entities found by the base model.\n",
      "================================================================================\n",
      "\n",
      "--- Analyzing Query: 'What is the market cap of Microsoft?' ---\n",
      "Token           | Lemma           | POS     | Dep        | Detailed Tag | Entity Type\n",
      "--------------------------------------------------------------------------------\n",
      "What            | what            | PRON    | attr       | WP           | -\n",
      "is              | be              | AUX     | ROOT       | VBZ          | -\n",
      "the             | the             | DET     | det        | DT           | -\n",
      "market          | market          | NOUN    | compound   | NN           | -\n",
      "cap             | cap             | NOUN    | nsubj      | NN           | -\n",
      "of              | of              | ADP     | prep       | IN           | -\n",
      "Microsoft       | Microsoft       | PROPN   | pobj       | NNP          | ORG\n",
      "?               | ?               | PUNCT   | punct      | .            | -\n",
      "\n",
      "Base Named Entities Found:\n",
      "- Entity: 'Microsoft', Label: ORG (Companies, agencies, institutions, etc.)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Basic Spacy pipeline test.\"\"\"\n",
    "\n",
    "# 'en_core_web_sm' is small and fast, good for starting.\n",
    "# 'en_core_web_md' or 'en_core_web_lg' are larger but more accurate.\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"Loaded 'en_core_web_sm' spaCy model.\")\n",
    "# Basic error handling if the model isn't downloaded\n",
    "except OSError:\n",
    "    print(\"spaCy model 'en_core_web_sm' not found.\")\n",
    "    print(\"Please run: python -m spacy download en_core_web_sm\")\n",
    "    # Depending on the environment, you might need to restart the kernel after download\n",
    "    # Or exit if the model is critical for subsequent steps\n",
    "    nlp = None # Set nlp to None to avoid errors later if model loading failed\n",
    "\n",
    "if nlp:\n",
    "    # Example Queries (taken from Step 1)\n",
    "    example_queries = [\n",
    "        \"Top 10 most valuable American IT companies.\", # Filtered Ranking\n",
    "        \"Show details for Apple Inc.\",                 # Company Info Lookup (using specific name from DB potential)\n",
    "        \"Every French company valued over 1B.\",        # Threshold Filtering\n",
    "        \"List all sectors available.\",                 # A potential simpler query\n",
    "        \"What is the market cap of Microsoft?\",        # Specific detail lookup\n",
    "    ]\n",
    "\n",
    "    # Process each query using spaCy\n",
    "    for query in example_queries:\n",
    "        print(f\"\\n--- Analyzing Query: '{query}' ---\")\n",
    "        \n",
    "        # Process the query with the loaded spaCy model\n",
    "        doc = nlp(query)\n",
    "        \n",
    "        # Print the analysis for each token\n",
    "        # Using a formatted table similar to the roadmap example\n",
    "        print(f\"{'Token':<15} | {'Lemma':<15} | {'POS':<7} | {'Dep':<10} | {'Detailed Tag':<7} | {'Entity Type'}\")\n",
    "        print(\"-\" * 80)\n",
    "        for token in doc:\n",
    "            print(f\"{token.text:<15} | {token.lemma_:<15} | {token.pos_:<7} | {token.dep_:<10} | {token.tag_:<12} | {token.ent_type_ if token.ent_type_ else '-'}\")\n",
    "\n",
    "        # Optional: Display Named Entities found by the base model (precursor to Step 5)\n",
    "        print(\"\\nBase Named Entities Found:\")\n",
    "        if doc.ents:\n",
    "            for ent in doc.ents:\n",
    "                print(f\"- Entity: '{ent.text}', Label: {ent.label_} ({spacy.explain(ent.label_)})\")\n",
    "        else:\n",
    "            print(\"- No named entities found by the base model.\")\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping NLP analysis because the spaCy model could not be loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "object address  : 0x1077fba60\n",
      "object refcount : 2\n",
      "object type     : 0x106566210\n",
      "object type name: KeyboardInterrupt\n",
      "object repr     : KeyboardInterrupt()\n",
      "lost sys.stderr\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nathan/Library/Python/3.11/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nathan/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.2.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Reinstalled pandas and updated numpy. Please RESTART THE KERNEL now.\n",
      "After restarting, re-run the previous cells (database setup, Step 4) and then try Step 5 again.\n"
     ]
    }
   ],
   "source": [
    "# Force reinstall pandas to ensure it's compiled against the current numpy version\n",
    "%pip uninstall pandas -y\n",
    "%pip install pandas --no-cache-dir\n",
    "\n",
    "# Also good practice to ensure numpy is reasonably up-to-date, though reinstalling pandas is key\n",
    "%pip install --upgrade numpy --no-cache-dir\n",
    "\n",
    "print(\"Reinstalled pandas and updated numpy. Please RESTART THE KERNEL now.\")\n",
    "print(\"After restarting, re-run the previous cells (database setup, Step 4) and then try Step 5 again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'en_core_web_sm' spaCy model already loaded.\n",
      "\n",
      "--- Loading Gazetteers from Database ---\n",
      "Loaded 491 unique terms for 'Security'.\n",
      "Loaded 11 unique terms for 'Sector'.\n",
      "Loaded 7 unique terms for 'Country'.\n",
      "Loaded 124 unique terms for 'Industry'.\n",
      "\n",
      "--- Setting up PhraseMatcher ---\n",
      "PhraseMatcher patterns added.\n",
      "\n",
      "--- Setting up EntityRuler ---\n",
      "EntityRuler already exists in pipeline.\n",
      "Added 35 patterns to EntityRuler.\n",
      "\n",
      "--- Analyzing Queries with Enhanced NER ---\n",
      "\n",
      "--- Analyzing Query: 'Top 10 most valuable American IT companies.' ---\n",
      "\n",
      "Identified Entities & Terms:\n",
      "- Text: 'Top', Label: RANKING_MODIFIER, Source: Pipeline (NER/Ruler)\n",
      "- Text: '10', Label: CARDINAL, Source: Pipeline (NER/Ruler)\n",
      "- Text: 'most', Label: RANKING_MODIFIER, Source: Pipeline (NER/Ruler)\n",
      "- Text: 'American', Label: NORP, Source: Pipeline (NER/Ruler)\n",
      "- Text: 'IT', Label: SECTOR_TERM, Source: Pipeline (NER/Ruler)\n",
      "================================================================================\n",
      "\n",
      "--- Analyzing Query: 'Show details for Apple Inc.' ---\n",
      "\n",
      "Identified Entities & Terms:\n",
      "- Text: 'Apple Inc.', Label: ORG, Source: Pipeline (NER/Ruler)\n",
      "================================================================================\n",
      "\n",
      "--- Analyzing Query: 'Every French company valued over 1B.' ---\n",
      "\n",
      "Identified Entities & Terms:\n",
      "- Text: 'French', Label: NORP, Source: Pipeline (NER/Ruler)\n",
      "- Text: 'valued', Label: VALUE_KEYWORD, Source: Pipeline (NER/Ruler)\n",
      "- Text: 'over', Label: COMPARISON_OP, Source: Pipeline (NER/Ruler)\n",
      "================================================================================\n",
      "\n",
      "--- Analyzing Query: 'List all sectors available.' ---\n",
      "\n",
      "Identified Entities & Terms:\n",
      "- Text: 'sectors', Label: COLUMN_SECTOR, Source: Pipeline (NER/Ruler)\n",
      "================================================================================\n",
      "\n",
      "--- Analyzing Query: 'What is the market cap of Microsoft?' ---\n",
      "\n",
      "Identified Entities & Terms:\n",
      "- Text: 'market cap', Label: VALUE_KEYWORD, Source: Pipeline (NER/Ruler)\n",
      "- Text: 'Microsoft', Label: ORG, Source: Pipeline (NER/Ruler)\n",
      "================================================================================\n",
      "\n",
      "--- Analyzing Query: 'Which German companies are in the Health Care sector?' ---\n",
      "\n",
      "Identified Entities & Terms:\n",
      "- Text: 'German', Label: NORP, Source: Pipeline (NER/Ruler)\n",
      "- Text: 'Health Care', Label: ORG, Source: Pipeline (NER/Ruler)\n",
      "- Text: 'sector', Label: COLUMN_SECTOR, Source: Pipeline (NER/Ruler)\n",
      "================================================================================\n",
      "\n",
      "--- Analyzing Query: 'Find companies worth more than 500 billion dollars' ---\n",
      "\n",
      "Identified Entities & Terms:\n",
      "- Text: 'worth', Label: VALUE_KEYWORD, Source: Pipeline (NER/Ruler)\n",
      "- Text: 'more than', Label: COMPARISON_OP, Source: Pipeline (NER/Ruler)\n",
      "- Text: '500 billion', Label: MONEY_VALUE, Source: Pipeline (NER/Ruler)\n",
      "================================================================================\n",
      "\n",
      "--- Analyzing Query: 'Show financials for Tesla' ---\n",
      "\n",
      "Identified Entities & Terms:\n",
      "- Text: 'financials', Label: SECTOR_TERM, Source: PhraseMatcher\n",
      "- Text: 'Tesla', Label: ORG, Source: Pipeline (NER/Ruler)\n",
      "================================================================================\n",
      "\n",
      "--- Analyzing Query: 'list info tech companies in the US' ---\n",
      "\n",
      "Identified Entities & Terms:\n",
      "- Text: 'info tech', Label: SECTOR_TERM, Source: Pipeline (NER/Ruler)\n",
      "- Text: 'US', Label: GPE, Source: Pipeline (NER/Ruler)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Adding Gazetteer, PhraseMatcher and EntityRuler to improve identification of key pieces of information.\"\"\"\n",
    "\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.pipeline import EntityRuler\n",
    "import sqlite3\n",
    "import pandas as pd # Needed for reading from DB\n",
    "\n",
    "\n",
    "# Configuration\n",
    "db_file = 'companies_database.db'\n",
    "table_name = 'companies'\n",
    "\n",
    "# Reload the spaCy model if it wasn't loaded or if the kernel restarted\n",
    "# Using the small model again for consistency\n",
    "try:\n",
    "    # nlp = spacy.load(\"en_core_web_sm\") # Reload if necessary\n",
    "    if 'nlp' not in locals() or nlp is None: # Check if nlp exists from previous cell\n",
    "         nlp = spacy.load(\"en_core_web_sm\")\n",
    "         print(\"Reloaded 'en_core_web_sm' spaCy model for Step 5.\")\n",
    "    else:\n",
    "        print(\"'en_core_web_sm' spaCy model already loaded.\")\n",
    "except OSError:\n",
    "    print(\"spaCy model 'en_core_web_sm' not found. Cannot proceed with Step 5.\")\n",
    "    print(\"Please run: python -m spacy download en_core_web_sm\")\n",
    "    nlp = None\n",
    "\n",
    "# Gazetteer Loading Function\n",
    "def load_terms_from_db(db_path, table, column_name):\n",
    "    \"\"\"Loads unique, non-null terms from a specific column in the SQLite DB.\"\"\"\n",
    "    terms = set() # Use a set for automatic deduplication\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        query = f\"SELECT DISTINCT \\\"{column_name}\\\" FROM {table} WHERE \\\"{column_name}\\\" IS NOT NULL AND \\\"{column_name}\\\" != ''\"\n",
    "        # Using pandas for robust reading, handles potential issues better\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        # Ensure the column exists before trying to access it\n",
    "        if column_name in df.columns:\n",
    "             # Convert to lowercase and strip whitespace for consistency before adding\n",
    "            terms.update(term.lower().strip() for term in df[column_name].astype(str))\n",
    "        else:\n",
    "             print(f\"Warning: Column '{column_name}' not found in table '{table}'.\")\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"SQLite error loading terms for '{column_name}': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred loading terms for '{column_name}': {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            \n",
    "    # Remove any empty strings that might have crept in\n",
    "    terms.discard('')\n",
    "    print(f\"Loaded {len(terms)} unique terms for '{column_name}'.\")\n",
    "    # print(f\"Sample terms for {column_name}: {list(terms)[:5]}\") # Optional: print samples\n",
    "    return list(terms) # Return as a list\n",
    "\n",
    "# Main Execution Block for Step 5\n",
    "if nlp:\n",
    "    # 1. Load Gazetteers from Database\n",
    "    # A gazetteer is a precompiled list of named entities (such as companies, countries, \n",
    "    # industries, and financial terms) used to improve Named Entity Recognition (NER) \n",
    "    # and query parsing in your NLP-to-SQL system.\n",
    "    print(\"\\n--- Loading Gazetteers from Database ---\")\n",
    "    unique_companies = load_terms_from_db(db_file, table_name, 'Security')\n",
    "    unique_sectors = load_terms_from_db(db_file, table_name, 'Sector')\n",
    "    unique_countries = load_terms_from_db(db_file, table_name, 'Country')\n",
    "    # Add Industries as well? Might be useful depending on query complexity\n",
    "    unique_industries = load_terms_from_db(db_file, table_name, 'Industry')\n",
    "\n",
    "    # Add common country variations or adjectives if needed\n",
    "    # Example: Map \"American\" or \"US\" to \"USA\" if \"USA\" is the value in your DB\n",
    "    country_mapping = {\n",
    "        \"american\": \"usa\",\n",
    "        \"us\": \"usa\",\n",
    "        \"u.s.\": \"usa\",\n",
    "        \"u.s.a\": \"usa\",\n",
    "        \"uk\": \"united kingdom\",\n",
    "        \"u.k.\": \"united kingdom\",\n",
    "        \"french\": \"france\",\n",
    "        \"german\": \"germany\",\n",
    "        # [...]\n",
    "    }\n",
    "    # Combine DB countries with mapped variations\n",
    "    all_country_terms = set(unique_countries)\n",
    "    all_country_terms.update(country_mapping.keys())\n",
    "\n",
    "\n",
    "    # 2. Setup PhraseMatcher\n",
    "    # PhraseMatcher is used to match exact phrases in a given text using word tokens. \n",
    "    # It is faster and more efficient than regex for multi-word phrases.\n",
    "    print(\"\\n--- Setting up PhraseMatcher ---\")\n",
    "    matcher = PhraseMatcher(nlp.vocab, attr='LOWER') # Case-insensitive matching\n",
    "\n",
    "    # Add patterns for each gazetteer list\n",
    "    # Use nlp.pipe for efficiency with many terms\n",
    "    company_patterns = list(nlp.pipe(unique_companies))\n",
    "    sector_patterns = list(nlp.pipe(unique_sectors))\n",
    "    # Use all_country_terms which includes variations\n",
    "    country_patterns = list(nlp.pipe(all_country_terms)) \n",
    "    industry_patterns = list(nlp.pipe(unique_industries))\n",
    "\n",
    "    # Add patterns to the matcher with specific labels\n",
    "    matcher.add(\"COMPANY_NAME\", company_patterns)\n",
    "    matcher.add(\"SECTOR_TERM\", sector_patterns)\n",
    "    matcher.add(\"COUNTRY_TERM\", country_patterns) # Includes variations now\n",
    "    matcher.add(\"INDUSTRY_TERM\", industry_patterns)\n",
    "    print(\"PhraseMatcher patterns added.\")\n",
    "\n",
    "\n",
    "    # 3. Setup EntityRuler for Patterns\n",
    "    # EntityRuler adds custom named entities (NER) based on token patterns and phrase matching.\n",
    "    print(\"\\n--- Setting up EntityRuler ---\")\n",
    "    # Try adding the ruler *before* NER to give custom patterns precedence\n",
    "    if \"entity_ruler\" not in nlp.pipe_names:\n",
    "        ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "        print(\"EntityRuler added to spaCy pipeline before NER.\")\n",
    "    else:\n",
    "        ruler = nlp.get_pipe(\"entity_ruler\")\n",
    "        print(\"EntityRuler already exists in pipeline.\")\n",
    "\n",
    "    # Define patterns for EntityRuler\n",
    "    # Using dictionaries for token attributes (see spaCy Matcher docs)\n",
    "    entity_patterns = [\n",
    "        # Monetary Values (simple B/M/T - can be expanded)\n",
    "        {\"label\": \"MONEY_VALUE\", \"pattern\": [{\"IS_DIGIT\": True}, {\"LOWER\": {\"IN\": [\"b\", \"bn\", \"billion\"]}}]},\n",
    "        {\"label\": \"MONEY_VALUE\", \"pattern\": [{\"IS_DIGIT\": True}, {\"LOWER\": {\"IN\": [\"m\", \"mn\", \"million\"]}}]},\n",
    "        {\"label\": \"MONEY_VALUE\", \"pattern\": [{\"IS_DIGIT\": True}, {\"LOWER\": {\"IN\": [\"t\", \"tn\", \"trillion\"]}}]},\n",
    "        # Handle \"$1B\" style - optional $ prefix\n",
    "        {\"label\": \"MONEY_VALUE\", \"pattern\": [{\"LOWER\":\"$\", \"OP\": \"?\"}, {\"IS_DIGIT\": True}, {\"LOWER\": {\"IN\": [\"b\", \"bn\", \"billion\"]}}]},\n",
    "        {\"label\": \"MONEY_VALUE\", \"pattern\": [{\"LOWER\":\"$\", \"OP\": \"?\"}, {\"IS_DIGIT\": True}, {\"LOWER\": {\"IN\": [\"m\", \"mn\", \"million\"]}}]},\n",
    "        {\"label\": \"MONEY_VALUE\", \"pattern\": [{\"LOWER\":\"$\", \"OP\": \"?\"}, {\"IS_DIGIT\": True}, {\"LOWER\": {\"IN\": [\"t\", \"tn\", \"trillion\"]}}]},\n",
    "        \n",
    "        # Ranking / Top N Indicators\n",
    "        {\"label\": \"RANKING_MODIFIER\", \"pattern\": [{\"LOWER\": \"top\"}]},\n",
    "        {\"label\": \"RANKING_MODIFIER\", \"pattern\": [{\"LOWER\": {\"IN\": [\"most\", \"highest\", \"largest\", \"biggest\"]}}]},\n",
    "        {\"label\": \"RANKING_MODIFIER\", \"pattern\": [{\"LOWER\": {\"IN\": [\"least\", \"lowest\", \"smallest\"]}}]}, # Handle bottom N?\n",
    "\n",
    "        # Comparison Operators/Phrases (for thresholds like \"over 1B\")\n",
    "        {\"label\": \"COMPARISON_OP\", \"pattern\": [{\"LOWER\": \"over\"}]},\n",
    "        {\"label\": \"COMPARISON_OP\", \"pattern\": [{\"LOWER\": \"above\"}]},\n",
    "        {\"label\": \"COMPARISON_OP\", \"pattern\": [{\"LOWER\": \"more\"}, {\"LOWER\": \"than\"}]},\n",
    "        {\"label\": \"COMPARISON_OP\", \"pattern\": [{\"LOWER\": \"greater\"}, {\"LOWER\": \"than\"}]},\n",
    "        {\"label\": \"COMPARISON_OP\", \"pattern\": [{\"LOWER\": \">\"}]}, # Handle symbol\n",
    "        {\"label\": \"COMPARISON_OP\", \"pattern\": [{\"LOWER\": \"under\"}]},\n",
    "        {\"label\": \"COMPARISON_OP\", \"pattern\": [{\"LOWER\": \"below\"}]},\n",
    "        {\"label\": \"COMPARISON_OP\", \"pattern\": [{\"LOWER\": \"less\"}, {\"LOWER\": \"than\"}]},\n",
    "        {\"label\": \"COMPARISON_OP\", \"pattern\": [{\"LOWER\": \"<\"}]}, # Handle symbol\n",
    "\n",
    "        # Keywords indicating value/market cap (can be expanded)\n",
    "        {\"label\": \"VALUE_KEYWORD\", \"pattern\": [{\"LOWER\": \"valued\"}]},\n",
    "        {\"label\": \"VALUE_KEYWORD\", \"pattern\": [{\"LOWER\": \"value\"}]},\n",
    "        {\"label\": \"VALUE_KEYWORD\", \"pattern\": [{\"LOWER\": \"marketcap\"}]},\n",
    "        {\"label\": \"VALUE_KEYWORD\", \"pattern\": [{\"LOWER\": \"market\"}, {\"LOWER\": \"cap\"}]}, # Multi-word\n",
    "        {\"label\": \"VALUE_KEYWORD\", \"pattern\": [{\"LOWER\": \"worth\"}]},\n",
    "\n",
    "        # Keywords for specific columns\n",
    "        {\"label\": \"COLUMN_SECTOR\", \"pattern\": [{\"LOWER\": \"sector\"}]},\n",
    "        {\"label\": \"COLUMN_SECTOR\", \"pattern\": [{\"LOWER\": \"sectors\"}]},\n",
    "        {\"label\": \"COLUMN_INDUSTRY\", \"pattern\": [{\"LOWER\": \"industry\"}]},\n",
    "        {\"label\": \"COLUMN_INDUSTRY\", \"pattern\": [{\"LOWER\": \"industries\"}]},\n",
    "        {\"label\": \"COLUMN_COUNTRY\", \"pattern\": [{\"LOWER\": \"country\"}]},\n",
    "        {\"label\": \"COLUMN_COUNTRY\", \"pattern\": [{\"LOWER\": \"countries\"}]},\n",
    "        {\"label\": \"COLUMN_FOUNDED\", \"pattern\": [{\"LOWER\": \"founded\"}]},\n",
    "         {\"label\": \"COLUMN_STOCKPRICE\", \"pattern\": [{\"LOWER\": \"stock\"}]}, # Simple match for stock price\n",
    "         {\"label\": \"COLUMN_STOCKPRICE\", \"pattern\": [{\"LOWER\": \"price\"}]},\n",
    "         {\"label\": \"COLUMN_STOCKPRICE\", \"pattern\": [{\"LOWER\": \"stockprice\"}]},\n",
    "        \n",
    "        # Add 'IT' specifically as a SECTOR_TERM if PhraseMatcher misses it due to tokenization\n",
    "        # Overwrite potentially wrong base NER tags\n",
    "        {\"label\": \"SECTOR_TERM\", \"pattern\": [{\"TEXT\": \"IT\"}], \"id\": \"information_technology\"}, # ID helps map later\n",
    "        {\"label\": \"SECTOR_TERM\", \"pattern\": [{\"LOWER\": \"info\"}, {\"LOWER\": \"tech\"}], \"id\": \"information_technology\"},\n",
    "        \n",
    "    ]\n",
    "\n",
    "    # Add patterns to the ruler\n",
    "    # Note: If patterns conflict, the first one added usually wins for EntityRuler.\n",
    "    # `overwrite_ents=True` allows ruler patterns to overwrite existing entities (from model or previous patterns)\n",
    "    ruler.add_patterns(entity_patterns)\n",
    "    # ruler.initialize(lambda: [], nlp=nlp, overwrite_ents=True) # Ensure it's initialized if adding patterns after loading nlp\n",
    "    print(f\"Added {len(entity_patterns)} patterns to EntityRuler.\")\n",
    "\n",
    "    # --- Process Example Queries with Enhanced NER ---\n",
    "    # Use the same queries as before\n",
    "    example_queries = [\n",
    "        \"Top 10 most valuable American IT companies.\",\n",
    "        \"Show details for Apple Inc.\",\n",
    "        \"Every French company valued over 1B.\",\n",
    "        \"List all sectors available.\",\n",
    "        \"What is the market cap of Microsoft?\",\n",
    "        \"Which German companies are in the Health Care sector?\", # New test case\n",
    "        \"Find companies worth more than 500 billion dollars\", # New test case\n",
    "        \"Show financials for Tesla\", # Test company name matching\n",
    "        \"list info tech companies in the US\", # Test variations\n",
    "    ]\n",
    "\n",
    "    print(\"\\n--- Analyzing Queries with Enhanced NER ---\")\n",
    "    for query in example_queries:\n",
    "        print(f\"\\n--- Analyzing Query: '{query}' ---\")\n",
    "\n",
    "        # Process with the pipeline (now includes EntityRuler)\n",
    "        doc = nlp(query)\n",
    "\n",
    "        # Apply the PhraseMatcher\n",
    "        phrase_matches = matcher(doc)\n",
    "\n",
    "        # --- Collect and Display Entities/Matches ---\n",
    "        # Store findings in a list for clarity, handling overlaps later if needed\n",
    "        found_items = []\n",
    "\n",
    "        # 1. Add Entities from the main pipeline (Base NER + EntityRuler)\n",
    "        for ent in doc.ents:\n",
    "            found_items.append({\n",
    "                \"text\": ent.text,\n",
    "                \"label\": ent.label_,\n",
    "                \"start_char\": ent.start_char,\n",
    "                \"end_char\": ent.end_char,\n",
    "                \"source\": \"Pipeline (NER/Ruler)\"\n",
    "            })\n",
    "\n",
    "        # 2. Add Matches from PhraseMatcher\n",
    "        # Be careful about adding duplicates if EntityRuler already caught it\n",
    "        # Simple approach: add if the exact span isn't already found by the pipeline\n",
    "        pipeline_spans = {(ent.start_char, ent.end_char) for ent in doc.ents}\n",
    "\n",
    "        for match_id, start, end in phrase_matches:\n",
    "            span = doc[start:end]\n",
    "            span_chars = (span.start_char, span.end_char)\n",
    "            \n",
    "            # Check if this exact span was already captured\n",
    "            if span_chars not in pipeline_spans:\n",
    "                 # Map match_id (string name) back to a label\n",
    "                label = nlp.vocab.strings[match_id]\n",
    "                \n",
    "                # Attempt to map country variations back to the DB value if needed\n",
    "                term_text = span.text\n",
    "                mapped_term = term_text # Default to original text\n",
    "                if label == \"COUNTRY_TERM\" and span.text.lower() in country_mapping:\n",
    "                    mapped_term = country_mapping[span.text.lower()] # Use the mapped value (e.g., \"usa\")\n",
    "                    \n",
    "                found_items.append({\n",
    "                    \"text\": term_text, # Keep original text for context\n",
    "                    \"label\": label,\n",
    "                    \"mapped_value\": mapped_term, # Store the potentially mapped value\n",
    "                    \"start_char\": span.start_char,\n",
    "                    \"end_char\": span.end_char,\n",
    "                    \"source\": \"PhraseMatcher\"\n",
    "                })\n",
    "\n",
    "\n",
    "        # Sort findings by start position for readability\n",
    "        found_items.sort(key=lambda item: item['start_char'])\n",
    "\n",
    "        print(\"\\nIdentified Entities & Terms:\")\n",
    "        if found_items:\n",
    "            for item in found_items:\n",
    "                details = f\"Text: '{item['text']}', Label: {item['label']}, Source: {item['source']}\"\n",
    "                if 'mapped_value' in item and item['mapped_value'] != item['text']:\n",
    "                    details += f\" (Mapped: '{item['mapped_value']}')\"\n",
    "                print(f\"- {details}\")\n",
    "        else:\n",
    "            print(\"- No specific entities or terms identified by custom rules or matchers.\")\n",
    "            # Optionally print base tokens again if nothing custom found\n",
    "            # print(\"\\nBasic Token Analysis:\")\n",
    "            # for token in doc:\n",
    "            #     print(f\"  {token.text:<10} {token.lemma_:<10} {token.pos_:<6} {token.dep_}\")\n",
    "\n",
    "\n",
    "        print(\"=\"*80)\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping Step 5 because the spaCy model could not be loaded.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
