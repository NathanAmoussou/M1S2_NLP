{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All cells can/must be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.13 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies imported successfully.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Dependencies import.\"\"\"\n",
    "\n",
    "import pandas as pd # For CSV manipulation and merging\n",
    "import sqlite3      # For embedded SQL manipulation (fuck SQL workbench)\n",
    "import os           # For files interaction\n",
    "\n",
    "print(\"Dependencies imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Files loading, Pandas DF parsing and inspection.\"\"\"\n",
    "\n",
    "# File paths\n",
    "sp500_file = 'Database_ressources/sp_500_companies_with_financial_information.csv'\n",
    "marketcap_file = 'Database_ressources/top_global_companies_by_market_cap.csv'\n",
    "db_file = 'companies_database.db'\n",
    "table_name = 'companies'\n",
    "\n",
    "# Pandas DF load and inspection\n",
    "try:\n",
    "    df_sp500 = pd.read_csv(sp500_file)\n",
    "    df_marketcap = pd.read_csv(marketcap_file)\n",
    "    \n",
    "    print(\"CSV files loaded successfully.\")\n",
    "    \n",
    "    # print(\"\\nS&P 500 info:\")\n",
    "    # df_sp500.info()\n",
    "    # print(df_sp500.head())\n",
    "    # print(\"\\nMarket Cap info:\")\n",
    "    # df_marketcap.info()\n",
    "    # print(df_marketcap.head())\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "    print(\"Please ensure the file paths are correct and the zip extraction worked.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S&P 500 DF columns renamed successfully.\n",
      "Top Global Market Cap DF columns renamed successfully.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"DF columns renaming.\"\"\"\n",
    "\n",
    "# S&P 500 DF columns renaming\n",
    "df1 = df_sp500[['Symbol', 'Security', 'GICS Sector', 'GICS Sub-Industry', 'Founded']].copy()\n",
    "df1.rename(columns={\n",
    "    'GICS Sector': 'Sector',\n",
    "    'GICS Sub-Industry': 'Industry'\n",
    "}, inplace=True)\n",
    "df1['Founded'] = df1['Founded'].astype(str).str.extract(r'(\\d{4})', expand=False)\n",
    "# print(\"Selected and renamed S&P 500 columns:\")\n",
    "# print(df1.head())\n",
    "\n",
    "print(\"S&P 500 DF columns renamed successfully.\")\n",
    "\n",
    "# Top Global Market Cap DF columns renaming\n",
    "df2 = df_marketcap[['Company Code', 'Marketcap', 'Stock Price', 'Country']].copy()\n",
    "df2.rename(columns={\n",
    "    'Company Code': 'Symbol', # IMPORTANT: Matching column for merge\n",
    "    'Stock Price': 'Stockprice'\n",
    "}, inplace=True)\n",
    "# print(\"Selected and renamed Top Global Market Cap columns:\")\n",
    "# print(df2.head())\n",
    "\n",
    "print(\"Top Global Market Cap DF columns renamed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Global Market Cap DF datas cleaned successfully.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Top Global Market Cap DF datas cleaning.\"\"\"\n",
    "\n",
    "# Top Global Market Cap DF cleaning (handle $, T, B, M, commas)\n",
    "def clean_marketcap(value):\n",
    "    if isinstance(value, (int, float)):\n",
    "        return value\n",
    "    if not isinstance(value, str):\n",
    "        return None\n",
    "    value = value.replace('$', '').replace(',', '').strip()\n",
    "    if 'T' in value:\n",
    "        # Handle potential spaces like '3.033 T'\n",
    "        return float(value.replace('T', '').strip()) * 1e12\n",
    "    elif 'B' in value:\n",
    "        return float(value.replace('B', '').strip()) * 1e9\n",
    "    elif 'M' in value:\n",
    "        return float(value.replace('M', '').strip()) * 1e6\n",
    "    try:\n",
    "        # Attempt direct conversion after basic cleaning\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return None # Return None if conversion still fails\n",
    "\n",
    "df2['Marketcap'] = df2['Marketcap'].apply(clean_marketcap)\n",
    "\n",
    "# Stockprice cleaning (handle $, commas)\n",
    "def clean_stockprice(value):\n",
    "    if isinstance(value, (int, float)):\n",
    "        return value\n",
    "    if not isinstance(value, str):\n",
    "        return None\n",
    "    # Remove '$' and ',' before converting\n",
    "    value = value.replace('$', '').replace(',', '').strip()\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return None # Return None if conversion fails\n",
    "\n",
    "df2['Stockprice'] = df2['Stockprice'].apply(clean_stockprice)\n",
    "\n",
    "# print(\"\\nCleaned Market Cap DF (showing Symbol, Marketcap, Stockprice, Country):\")\n",
    "# print(df2.head())\n",
    "# print(\"\\nData types after cleaning:\")\n",
    "# df2.info()\n",
    "\n",
    "print(\"Top Global Market Cap DF datas cleaned successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF merged successfully.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"DataFrames merging.\"\"\"\n",
    "\n",
    "# Merge based on the 'Symbol' column.\n",
    "# 'inner' merge keeps only symbols present in BOTH DataFrames.\n",
    "merged_df = pd.merge(df1, df2, on='Symbol', how='inner')\n",
    "\n",
    "# Check for duplicates in the merging key ('Symbol') before merge if issues arise\n",
    "# print(\"Duplicates in df1 Symbol:\", df1.duplicated('Symbol').sum())\n",
    "# print(\"Duplicates in df2 Symbol:\", df2.duplicated('Symbol').sum())\n",
    "\n",
    "# Handle potential duplicates after merge if needed (e.g., based on Marketcap)\n",
    "merged_df = merged_df.sort_values('Marketcap', ascending=False).drop_duplicates('Symbol', keep='first')\n",
    "\n",
    "# print(f\"Merged DataFrame contains {len(merged_df)} rows.\")\n",
    "# print(\"Merged DataFrame head:\")\n",
    "# print(merged_df.head())\n",
    "# merged_df.info()\n",
    "\n",
    "print(\"DF merged successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF preparation for SQL successful.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"DF preparation for SQL.\"\"\"\n",
    "\n",
    "# Define the final order of columns matching the target schema\n",
    "final_columns = ['Symbol', 'Security', 'Sector', 'Industry', 'Founded', 'Marketcap', 'Stockprice', 'Country']\n",
    "\n",
    "# Ensure all required columns exist and select them in the correct order\n",
    "# Check if all columns are present (should be after merge)\n",
    "missing_cols = [col for col in final_columns if col not in merged_df.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Warning: The following columns are missing from the merged DataFrame: {missing_cols}\")\n",
    "    # Handle missing columns if necessary (e.g., add them with None)\n",
    "    # for col in missing_cols:\n",
    "    #     merged_df[col] = None\n",
    "\n",
    "# Select and reorder columns\n",
    "final_df = merged_df[final_columns].copy() # Use .copy() to avoid SettingWithCopyWarning on potential future modifications\n",
    "\n",
    "# print(\"Final DataFrame structure for SQL:\")\n",
    "# print(final_df.head())\n",
    "# final_df.info()\n",
    "\n",
    "print(\"DF preparation for SQL successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to SQLite database: companies_database.db\n",
      "Data successfully imported into table 'companies' in database 'companies_database.db'\n",
      "\n",
      "Verifying import - First 5 rows from SQL database:\n",
      "  Symbol                 Security                  Sector  \\\n",
      "0   MSFT                Microsoft  Information Technology   \n",
      "1   AAPL               Apple Inc.  Information Technology   \n",
      "2   GOOG  Alphabet Inc. (Class C)  Communication Services   \n",
      "3   AMZN                   Amazon  Consumer Discretionary   \n",
      "4   NVDA                   Nvidia  Information Technology   \n",
      "\n",
      "                                     Industry Founded     Marketcap  \\\n",
      "0                            Systems Software    1975  3.033000e+12   \n",
      "1  Technology Hardware, Storage & Peripherals    1977  2.951000e+12   \n",
      "2                Interactive Media & Services    1998  1.909000e+12   \n",
      "3                            Broadline Retail    1994  1.653000e+12   \n",
      "4                              Semiconductors    1993  1.522000e+12   \n",
      "\n",
      "   Stockprice Country  \n",
      "0      407.21     USA  \n",
      "1      190.92     USA  \n",
      "2      153.46     USA  \n",
      "3      160.05     USA  \n",
      "4      616.49     USA  \n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SQLite database creation.\"\"\"\n",
    "\n",
    "# Connection to SQLite Database (creates the file if it doesn't exist)\n",
    "conn = sqlite3.connect(db_file)\n",
    "cursor = conn.cursor()\n",
    "print(f\"Connected to SQLite database: {db_file}\")\n",
    "\n",
    "# Use pandas to_sql to create table and insert data\n",
    "# if_exists='replace': Drops table if exists, then creates new and inserts. Good for reruns.\n",
    "# if_exists='append': Adds data to existing table.\n",
    "# if_exists='fail': Raises error if table exists.\n",
    "try:\n",
    "    final_df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "    print(f\"Data successfully imported into table '{table_name}' in database '{db_file}'\")\n",
    "\n",
    "    # Verify by reading back some data\n",
    "    print(\"\\nVerifying import - First 5 rows from SQL database:\")\n",
    "    verify_df = pd.read_sql(f\"SELECT * FROM {table_name} LIMIT 5\", conn)\n",
    "    print(verify_df)\n",
    "\n",
    "except sqlite3.Error as e:\n",
    "    print(f\"SQLite error during import: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during SQL import: {e}\")\n",
    "finally:\n",
    "    # Commit changes and close connection regardless of success/failure\n",
    "    if conn:\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        print(\"Database connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
